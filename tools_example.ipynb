{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da02914d",
   "metadata": {},
   "source": [
    "### Example of FC based on API Client and Model Inference class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "watsonx_credentials = {\n",
    "    \"apikey\": \"\",\n",
    "    \"url\": \"https://yp-qa.ml.cloud.ibm.com\",\n",
    "    \"project_id\":  \"\"\n",
    "}\n",
    "\n",
    "model = ModelInference(\n",
    "    model_id=\"meta-llama/llama-3-2-1b-instruct\",\n",
    "    api_client=APIClient(watsonx_credentials),\n",
    "    project_id=watsonx_credentials[\"project_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfb4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"add\",\n",
    "        \"description\": \"Adds the values a and b to get a sum.\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"a\": {\n",
    "              \"description\": \"A number value\",\n",
    "              \"type\": \"number\"\n",
    "            },\n",
    "            \"b\": {\n",
    "              \"description\": \"A number value\",\n",
    "               \"type\": \"number\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"a\",\n",
    "            \"b\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"multiply\",\n",
    "        \"description\": \"Multiplies the values a and b.\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"a\": {\n",
    "              \"description\": \"A number value\",\n",
    "              \"type\": \"number\"\n",
    "            },\n",
    "            \"b\": {\n",
    "              \"description\": \"A number value\",\n",
    "               \"type\": \"number\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"a\",\n",
    "            \"b\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_tools = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is 2 times 5?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f85b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.chat(messages=messages_tools, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hi! How are you doing?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a98600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.chat(messages=messages, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62b121",
   "metadata": {},
   "source": [
    "### Mocking actual eval.pl with WML support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be217bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, argparse\n",
    "from src.instruct_data_prep import get_instruct_data\n",
    "from tqdm import tqdm\n",
    "from src.utils import read_jsonlines, write_jsonlines\n",
    "\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d786f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select = {\n",
    "    \"granite-3-3-8b-instruct\": {\n",
    "        \"model\": \"ibm-granite/granite-3.3-8b-instruct\",\n",
    "        \"model_name\": \"granite-3.3-8b-instruct\",\n",
    "        \"model_name_wml\": \"ibm/granite-3-3-8b-instruct\"\n",
    "    },\n",
    "    \"Llama-3.3-70B-Instruct\": {\n",
    "        \"model\": \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "        \"model_name\": \"Llama-3.3-70B-Instruct\",\n",
    "        \"model_name_wml\": \"meta-llama/llama-3-3-70b-instruct\"\n",
    "    },\n",
    "    \"Llama-3.1-70B-Instruct\": {\n",
    "        \"model\": \"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "        \"model_name\": \"Llama-3.1-70B-Instruct\",\n",
    "        \"model_name_wml\": \"meta-llama/llama-3-1-70b-instruct\"\n",
    "    }\n",
    "}\n",
    "\n",
    "model = 'Llama-3.1-70B-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99514fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "watsonx_credentials = {\n",
    "    \"apikey\": \"\",\n",
    "    \"url\": \"https://yp-qa.ml.cloud.ibm.com\",\n",
    "    \"project_id\":  \"\"\n",
    "}\n",
    "\n",
    "args = {}\n",
    "generate_params = {\n",
    "    GenParams.DECODING_METHOD: (\n",
    "        \"greedy\" if not args.get(\"do_sample\", None) else \"sample\"\n",
    "    ),\n",
    "    GenParams.LENGTH_PENALTY: args.get(\"length_penalty\", None),\n",
    "    GenParams.TEMPERATURE: args.get(\"temperature\", 0.0),\n",
    "    GenParams.TOP_P: args.get(\"top_p\", None),\n",
    "    GenParams.TOP_K: args.get(\"top_k\", None),\n",
    "    GenParams.RANDOM_SEED: args.get(\"seed\", 42),\n",
    "    GenParams.REPETITION_PENALTY: args.get(\"repetition_penalty\", None),\n",
    "    GenParams.MIN_NEW_TOKENS: args.get(\"min_new_tokens\", None),\n",
    "    GenParams.MAX_NEW_TOKENS: args.get(\"max_new_tokens\", 1000),\n",
    "    GenParams.STOP_SEQUENCES: args.get(\"stop_sequences\", None),\n",
    "    GenParams.TIME_LIMIT: args.get(\"time_limit\", None),\n",
    "    GenParams.TRUNCATE_INPUT_TOKENS: args.get(\"truncate_input_tokens\", None),\n",
    "    # This is required to get token likelihood\n",
    "    # GenParams.RETURN_OPTIONS: {\n",
    "    #     \"generated_tokens\": True,\n",
    "    #     \"input_tokens\": True,\n",
    "    #     \"token_logprobs\": True,\n",
    "    #     \"token_ranks\": True,\n",
    "    # },\n",
    "}\n",
    "generate_params = {i: v for i, v in generate_params.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95681e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = [\n",
    "    '',\n",
    "    '--model', model_select[model][\"model\"],\n",
    "    '--model_name', model_select[model][\"model_name\"],\n",
    "    '--save_directory', 'results',\n",
    "    '--dataset', '/Users/piotrhelm/IBM/NESTFUL/data_v2/nestful_data.jsonl',\n",
    "    '--icl_count', '5',\n",
    "    '--temperature', '0.0',\n",
    "    '--max_tokens', '1000',\n",
    "    '--batch_size', '32'\n",
    "]\n",
    "\n",
    "# Argument parser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model\", type=str)\n",
    "parser.add_argument(\"--model_name\", type=str)\n",
    "parser.add_argument(\"--save_directory\", type=str, default='results')\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"ibm-research/nestful\")\n",
    "parser.add_argument(\"--icl_count\", default=3, type=int)  \n",
    "parser.add_argument(\"--temperature\", type=float, default=0.0)\n",
    "parser.add_argument(\"--max_tokens\", type=int, default=1000)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"### Loading Data...\")\n",
    "\n",
    "data = read_jsonlines(args.dataset)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i][\"tools\"] = json.dumps(data[i][\"tools\"])\n",
    "    data[i][\"gold_answer\"] = json.dumps(data[i][\"gold_answer\"])\n",
    "    data[i][\"output\"] = json.dumps(data[i][\"output\"])\n",
    "\n",
    "print(\"### Preparing Instruct Data...\")\n",
    "instruct_data = get_instruct_data(data, args.model, args.model_name, args.icl_count)\n",
    "print(\"### Loading Model...\")\n",
    "llm = ModelInference(\n",
    "    model_id=model_select[model][\"model_name_wml\"],\n",
    "    api_client=APIClient(watsonx_credentials),\n",
    "    project_id=watsonx_credentials[\"project_id\"],\n",
    ")\n",
    "    \n",
    "prompts = [sample[\"input\"] for sample in instruct_data][:100]\n",
    "\n",
    "print(\"### Starting Generation...\")\n",
    "response, output_list = [], []\n",
    "for idx, prompt in tqdm(enumerate(prompts), total=len(prompts)):\n",
    "    output = llm.generate_text(prompt=prompt, params=generate_params)\n",
    "    response.append(output)\n",
    "    \n",
    "for idx in range(len(response)):\n",
    "    temp = instruct_data[idx]\n",
    "    temp[\"generated_text\"] = response[idx]\n",
    "    output_list.append(temp)\n",
    "\n",
    "print(\"### Saving...\")\n",
    "save_path = os.path.join(args.save_directory, f\"nestful_{args.icl_count}\", args.model_name, \"output.jsonl\")\n",
    "print(f\"### Save Path: {save_path}\")\n",
    "os.makedirs(os.path.join(args.save_directory, f\"nestful_{args.icl_count}\", args.model_name), exist_ok=True)\n",
    "write_jsonlines(output_list, save_path)\n",
    "\n",
    "print(f\"### DONE...!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
